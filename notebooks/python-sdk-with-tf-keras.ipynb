{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amna9090/Flutter-Demos/blob/master/notebooks/python-sdk-with-tf-keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7583a486-afd6-42d8-934b-fdb33a6f3362",
      "metadata": {
        "tags": [],
        "id": "7583a486-afd6-42d8-934b-fdb33a6f3362"
      },
      "source": [
        "# Using the Edge Impulse Python SDK with TensorFlow and Keras\n",
        "\n",
        "<!--- Do not modify the markdown for this example directly! It is generated from a notebook in https://github.com/edgeimpulse/notebooks --->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "574b4630-cb17-4bab-8866-ba292e1bc2c8",
      "metadata": {
        "tags": [],
        "id": "574b4630-cb17-4bab-8866-ba292e1bc2c8"
      },
      "source": [
        "[![View in Edge Impulse docs](https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/ei-badge.svg)](https://docs.edgeimpulse.com/docs/tutorials/ml-and-data-engineering/ei-python-sdk/python-sdk-with-tf-keras)\n",
        "[![Open in Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/edgeimpulse/notebooks/blob/main/notebooks/python-sdk-with-tf-keras.ipynb)\n",
        "[![View on GitHub](https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/badge-view-on-github.svg)](https://github.com/edgeimpulse/notebooks/blob/main/notebooks/python-sdk-with-tf-keras.ipynb)\n",
        "[![Download notebook](https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/badge-download-notebook.svg)](https://raw.githubusercontent.com/edgeimpulse/notebooks/main/notebooks/python-sdk-with-tf-keras.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867045bb-14c2-41c2-a417-0426470df85b",
      "metadata": {
        "tags": [],
        "id": "867045bb-14c2-41c2-a417-0426470df85b"
      },
      "source": [
        "[TensorFlow](https://www.tensorflow.org/) is an open source library for training machine learning models. [Keras](https://keras.io/) is an open source Python library that makes creating neural networks in TensorFlow much easier. We use these two libraries together to very quickly train a model to identify handwritten digits. From there, we use the Edge Impulse Python SDK library to profile the model to see how inference will perform on a target edge device. Then, we use the SDK again to convert our trained model to a C++ library that can be deployed to an edge hardware platform, such as a microcontroller.\n",
        "\n",
        "Follow the code below to see how to train a simple machine learning model and deploy it to a C++ library using Edge Impulse.\n",
        "\n",
        "To learn more about using the Python SDK, please see: [Edge Impulse Python SDK Overview](https://docs.edgeimpulse.com/docs/tools/edge-impulse-python-sdk)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e0de311a-de4c-4fe1-8dd9-e7b2206217d0",
      "metadata": {
        "id": "e0de311a-de4c-4fe1-8dd9-e7b2206217d0",
        "outputId": "fea28037-9e3a-4afd-f5ec-b67053148f13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.19.0 in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting edgeimpulse\n",
            "  Downloading edgeimpulse-1.0.18-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (0.5.3)\n",
            "Collecting edgeimpulse-api<2.0.0,>=1.61.23 (from edgeimpulse)\n",
            "  Downloading edgeimpulse_api-1.79.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting python-socketio<6.0.0,>=5.8.0 (from python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading python_socketio-5.14.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.19.0) (0.45.1)\n",
            "Collecting aenum<4.0.0,>=3.1.11 (from edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse)\n",
            "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.17 in /usr/local/lib/python3.12/dist-packages (from edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse) (2.11.10)\n",
            "Requirement already satisfied: python_dateutil<3.0.0,>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse) (2.9.0.post0)\n",
            "Collecting urllib3<2.0.0,>=1.25.3 (from edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (0.17.0)\n",
            "Collecting bidict>=0.21.0 (from python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting python-engineio>=4.11.0 (from python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading python_engineio-4.12.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.12/dist-packages (from python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (1.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (3.1.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.17->edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.17->edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.17->edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse) (0.4.2)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.11.0->python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.0) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.0) (0.1.2)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading wsproto-1.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: h11<1,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (0.16.0)\n",
            "Downloading edgeimpulse-1.0.18-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading edgeimpulse_api-1.79.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_socketio-5.14.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
            "Downloading python_engineio-4.12.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading wsproto-1.3.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: aenum, wsproto, urllib3, bidict, simple-websocket, python-engineio, edgeimpulse-api, python-socketio, edgeimpulse\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "Successfully installed aenum-3.1.16 bidict-0.23.1 edgeimpulse-1.0.18 edgeimpulse-api-1.79.0 python-engineio-4.12.3 python-socketio-5.14.3 simple-websocket-1.1.0 urllib3-1.26.20 wsproto-1.3.1\n"
          ]
        }
      ],
      "source": [
        "# If you have not done so already, install the following dependencies\n",
        "!python -m pip install tensorflow==2.19.0 edgeimpulse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2f85b7c9-e76b-459e-ac37-4b348cbb5906",
      "metadata": {
        "tags": [],
        "id": "2f85b7c9-e76b-459e-ac37-4b348cbb5906"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import edgeimpulse as ei"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aef50a1-0a2d-4743-bfc3-de0a9755a87b",
      "metadata": {
        "tags": [],
        "id": "8aef50a1-0a2d-4743-bfc3-de0a9755a87b"
      },
      "source": [
        "You will need to obtain an API key from an Edge Impulse project. Log into [edgeimpulse.com](https://edgeimpulse.com/) and create a new project. Open the project, navigate to **Dashboard** and click on the **Keys** tab to view your API keys. Double-click on the API key to highlight it, right-click, and select **Copy**.\n",
        "\n",
        "![Copy API key from Edge Impulse project](https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/python-sdk-copy-ei-api-key.png)\n",
        "\n",
        "Note that you do not actually need to use the project in the Edge Impulse Studio. We just need the API Key.\n",
        "\n",
        "Paste that API key string in the `ei.API_KEY` value in the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3429e02d-5188-4215-97c7-5a50b854b06b",
      "metadata": {
        "tags": [],
        "id": "3429e02d-5188-4215-97c7-5a50b854b06b"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "ei.API_KEY = \"ei_b1897d1aa327990ca509d54cf0ff4480d6a1287e915de6042ae120ae01585133\" # Change this to your Edge Impulse API key\n",
        "labels = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
        "num_classes = len(labels)\n",
        "deploy_filename = \"mnist_cpp.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd9078d0-d5a5-4a9f-96f1-0faecb4e2b1c",
      "metadata": {
        "tags": [],
        "id": "dd9078d0-d5a5-4a9f-96f1-0faecb4e2b1c"
      },
      "source": [
        "## Train a machine learning model\n",
        "\n",
        "We want to create a classifier that can uniquely identify handwritten digits. To start, we will use TensorFlow and Keras to train a very simple convolutional neural network (CNN) on the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, which consists of handwritten digits from 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0a0abd03-9473-4272-b97d-f59cefa44995",
      "metadata": {
        "tags": [],
        "id": "0a0abd03-9473-4272-b97d-f59cefa44995",
        "outputId": "2aaf6ad8-455d-49c1-c933-60510907414e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = keras.utils.normalize(x_train, axis=1)\n",
        "x_test = keras.utils.normalize(x_test, axis=1)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "input_shape = x_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ba42755e-b13c-4e84-a016-4e4fcf4be9f6",
      "metadata": {
        "tags": [],
        "id": "ba42755e-b13c-4e84-a016-4e4fcf4be9f6",
        "outputId": "a3a19e82-9bbe-4cf2-a28a-6fb1edb2c7a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Build the model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32, activation='relu', input_shape=input_shape),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d6ddf625-43c9-40da-9c44-7fbbbea8b572",
      "metadata": {
        "tags": [],
        "id": "d6ddf625-43c9-40da-9c44-7fbbbea8b572",
        "outputId": "838cf862-bb43-4440-ceaa-7f618f610666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.7099\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9335 - loss: 0.2329\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1804\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1482\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1288\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b7b4c8ca3c0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dc2b0ab6-e2d0-4448-9545-4870e5b2d101",
      "metadata": {
        "tags": [],
        "id": "dc2b0ab6-e2d0-4448-9545-4870e5b2d101",
        "outputId": "0b71dbdc-76a4-4ba2-de86-a360a1a9fb54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.14768247306346893\n",
            "Test accuracy: 0.9563999772071838\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test loss: {score[0]}\")\n",
        "print(f\"Test accuracy: {score[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e04b239-80c6-43e0-87e0-e3a41b8457db",
      "metadata": {
        "tags": [],
        "id": "4e04b239-80c6-43e0-87e0-e3a41b8457db"
      },
      "source": [
        "## Profile your model\n",
        "\n",
        "To start, we need to list the possible target devices we can use for profiling. We need to pick from this list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1b622df2-9745-4c93-969f-35de2ff10df6",
      "metadata": {
        "tags": [],
        "id": "1b622df2-9745-4c93-969f-35de2ff10df6",
        "outputId": "e85ff8cb-bcc0-42ee-e3ca-9e84337b0b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alif-he',\n",
              " 'alif-hp',\n",
              " 'ambiq-apollo4',\n",
              " 'ambiq-apollo5',\n",
              " 'arduino-nano-33-ble',\n",
              " 'arduino-nicla-vision',\n",
              " 'arduino-nicla-vision-m4',\n",
              " 'portenta-h7',\n",
              " 'arduino-unoq',\n",
              " 'brainchip-akd1000',\n",
              " 'brickml',\n",
              " 'cortex-m4f-80mhz',\n",
              " 'cortex-m7-216mhz',\n",
              " 'nxp-imx93-npu',\n",
              " 'nxp-imx93-cpu',\n",
              " 'espressif-esp32',\n",
              " 'himax-we-i',\n",
              " 'himax-wiseeye2',\n",
              " 'himax-wiseeye2-ethos',\n",
              " 'imdt-v2h-cpu',\n",
              " 'imdt-v2h',\n",
              " 'infineon-cy8ckit-062s2',\n",
              " 'infineon-cy8ckit-062-ble',\n",
              " 'mbp-16-2020',\n",
              " 'mbp-16-2021',\n",
              " 'memryx-mx3',\n",
              " 'microchip-sama7d65',\n",
              " 'microchip-sama7g54',\n",
              " 'nordic-nrf52840-dk',\n",
              " 'nordic-nrf5340-dk',\n",
              " 'nordic-nrf54l15-dk',\n",
              " 'nordic-nrf9151-dk',\n",
              " 'nordic-nrf9160-dk',\n",
              " 'nordic-nrf9161-dk',\n",
              " 'jetson-nano',\n",
              " 'jetson-orin-nx',\n",
              " 'jetson-orin-nano',\n",
              " 'openmv-h7p',\n",
              " 'particle-boron',\n",
              " 'particle-p2',\n",
              " 'qualcomm-rb3-gen2-dk',\n",
              " 'raspberry-pi-4',\n",
              " 'raspberry-pi-5',\n",
              " 'raspberry-pi-rp2040',\n",
              " 'raspberry-pi-rp2350',\n",
              " 'renesas-ck-ra6m5',\n",
              " 'renesas-ek-ra8d1',\n",
              " 'renesas-rzg2l',\n",
              " 'renesas-rzv2h-cpu',\n",
              " 'renesas-rzv2h',\n",
              " 'renesas-rzv2l-cpu',\n",
              " 'renesas-rzv2l',\n",
              " 'st-iot-discovery-kit',\n",
              " 'st-stm32n6',\n",
              " 'seeed-sense-cap',\n",
              " 'wio-terminal',\n",
              " 'seeed-vision-ai',\n",
              " 'silabs-xg24',\n",
              " 'silabs-thunderboard-sense-2',\n",
              " 'sony-spresense',\n",
              " 'synaptics-ka10000',\n",
              " 'ti-am62a',\n",
              " 'ti-am68a',\n",
              " 'ti-launchxl',\n",
              " 'ti-tda4vm',\n",
              " 'thundercomm-rubik-pi-3']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# List the available profile target devices\n",
        "ei.model.list_profile_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaaaef69-1ba2-4ffd-bbe6-88ca299c8ee7",
      "metadata": {
        "tags": [],
        "id": "eaaaef69-1ba2-4ffd-bbe6-88ca299c8ee7"
      },
      "source": [
        "You should see a list printed such as:\n",
        "\n",
        "```\n",
        "['alif-he',\n",
        " 'alif-hp',\n",
        " 'arduino-nano-33-ble',\n",
        " 'arduino-nicla-vision',\n",
        " 'portenta-h7',\n",
        " 'brainchip-akd1000',\n",
        " 'cortex-m4f-80mhz',\n",
        " 'cortex-m7-216mhz',\n",
        " ...\n",
        " 'ti-tda4vm']\n",
        "```\n",
        "\n",
        "A common option is the `cortex-m4f-80mhz`, as this is a relatively low-power microcontroller family. From there, we can use the Edge Impulse Python SDK to generate a profile for your model to ensure it fits on your target hardware and meets your timing requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3c16e2ab-0c50-483e-8d2e-01c2dd48be23",
      "metadata": {
        "tags": [],
        "id": "3c16e2ab-0c50-483e-8d2e-01c2dd48be23",
        "outputId": "fe0bae08-6ab1-4005-e426-69e7def78979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpgfhwsqja/saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135769424670992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135769424673488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135769424673680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135769424674448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Target results for float32:\n",
            "===========================\n",
            "{\n",
            "    \"variant\": \"float32\",\n",
            "    \"device\": \"cortex-m4f-80mhz\",\n",
            "    \"tfliteFileSizeBytes\": 105312,\n",
            "    \"isSupportedOnMcu\": true,\n",
            "    \"memory\": {\n",
            "        \"tflite\": {\n",
            "            \"ram\": 11838,\n",
            "            \"rom\": 138936,\n",
            "            \"arenaSize\": 11622\n",
            "        },\n",
            "        \"eon\": {\n",
            "            \"ram\": 8560,\n",
            "            \"rom\": 217616,\n",
            "            \"arenaSize\": 6960\n",
            "        }\n",
            "    },\n",
            "    \"timePerInferenceMs\": 3,\n",
            "    \"customMetrics\": [],\n",
            "    \"hasPerformance\": true\n",
            "}\n",
            "\n",
            "\n",
            "Performance on device types:\n",
            "============================\n",
            "{\n",
            "    \"variant\": \"float32\",\n",
            "    \"lowEndMcu\": {\n",
            "        \"description\": \"Estimate for a Cortex-M0+ or similar, running at 40MHz\",\n",
            "        \"timePerInferenceMs\": 84,\n",
            "        \"memory\": {\n",
            "            \"tflite\": {\n",
            "                \"ram\": 11646,\n",
            "                \"rom\": 132216\n",
            "            },\n",
            "            \"eon\": {\n",
            "                \"ram\": 8416,\n",
            "                \"rom\": 217424\n",
            "            }\n",
            "        },\n",
            "        \"supported\": true\n",
            "    },\n",
            "    \"highEndMcu\": {\n",
            "        \"description\": \"Estimate for a Cortex-M7 or other high-end MCU/DSP, running at 240MHz\",\n",
            "        \"timePerInferenceMs\": 2,\n",
            "        \"memory\": {\n",
            "            \"tflite\": {\n",
            "                \"ram\": 11838,\n",
            "                \"rom\": 138936\n",
            "            },\n",
            "            \"eon\": {\n",
            "                \"ram\": 8560,\n",
            "                \"rom\": 217616\n",
            "            }\n",
            "        },\n",
            "        \"supported\": true\n",
            "    },\n",
            "    \"highEndMcuPlusAccelerator\": {\n",
            "        \"description\": \"Most accelerators only accelerate quantized models.\",\n",
            "        \"timePerInferenceMs\": 2,\n",
            "        \"memory\": {\n",
            "            \"tflite\": {\n",
            "                \"ram\": 11838,\n",
            "                \"rom\": 138936\n",
            "            },\n",
            "            \"eon\": {\n",
            "                \"ram\": 8560,\n",
            "                \"rom\": 217616\n",
            "            }\n",
            "        },\n",
            "        \"supported\": true\n",
            "    },\n",
            "    \"mpu\": {\n",
            "        \"description\": \"Estimate for a Cortex-A72, x86 or other mid-range microprocessor running at 1.5GHz\",\n",
            "        \"timePerInferenceMs\": 1,\n",
            "        \"rom\": 105312.0,\n",
            "        \"supported\": true\n",
            "    },\n",
            "    \"gpuOrMpuAccelerator\": {\n",
            "        \"description\": \"Estimate for a GPU or high-end neural network accelerator\",\n",
            "        \"timePerInferenceMs\": 1,\n",
            "        \"rom\": 105312.0,\n",
            "        \"supported\": true\n",
            "    }\n",
            "}\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Estimate the RAM, ROM, and inference time for our model on the target hardware family\n",
        "try:\n",
        "    profile = ei.model.profile(model=model,\n",
        "                               device='cortex-m4f-80mhz')\n",
        "    print(profile.summary())\n",
        "except Exception as e:\n",
        "    print(f\"Could not profile: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29e4bc88-032a-4d8a-8b3a-4cbf2ec5d778",
      "metadata": {
        "id": "29e4bc88-032a-4d8a-8b3a-4cbf2ec5d778"
      },
      "source": [
        "## Deploy your model\n",
        "\n",
        "Once you are happy with the performance of the model, you can deploy it to a number of possible hardware targets. To see the available hardware targets, run the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ee30330d-6ff2-4733-8c37-8d90e3da6d78",
      "metadata": {
        "tags": [],
        "id": "ee30330d-6ff2-4733-8c37-8d90e3da6d78",
        "outputId": "84cace35-360f-42cf-8323-39a49c848693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['zip',\n",
              " 'zip-linux',\n",
              " 'android-cpp',\n",
              " 'arduino',\n",
              " 'zephyr',\n",
              " 'tinkergen',\n",
              " 'cubemx',\n",
              " 'wasm',\n",
              " 'wasm-browser-simd',\n",
              " 'wasm-node-simd',\n",
              " 'tensorrt',\n",
              " 'ethos-alif-ensemble-e7-hp',\n",
              " 'ethos-alif-ensemble-e7-he',\n",
              " 'ethos-nxp-imx93',\n",
              " 'ethos-alif-ensemble-e7-he-cmsis-pack',\n",
              " 'ethos-alif-ensemble-e7-hp-cmsis-pack',\n",
              " 'ethos-himax-wiseeye2',\n",
              " 'ethos-u85',\n",
              " 'ethos-u85-cmsis-pack',\n",
              " 'synaptics-tensaiflow-lib',\n",
              " 'drp-ai-lib',\n",
              " 'drp-ai-tvm-lib',\n",
              " 'drp-ai-tvm-i8-lib',\n",
              " 'meta-tf',\n",
              " 'tidl-lib',\n",
              " 'memryx-dfp',\n",
              " 'tidl-lib-am62a',\n",
              " 'tidl-lib-am68a',\n",
              " 'slcc',\n",
              " 'think-silicon-neox',\n",
              " 'disco-l475vg',\n",
              " 'ambiq-apollo4',\n",
              " 'ambiq-apollo5',\n",
              " 'arduino-nano-33-ble-sense',\n",
              " 'arduino-nicla-vision',\n",
              " 'runner-linux-aarch64-advantech-icam540',\n",
              " 'espressif-esp32',\n",
              " 'raspberry-pi-rp2040',\n",
              " 'raspberry-pi-pico2',\n",
              " 'raspberry-pi-pico2-w',\n",
              " 'arduino-portenta-h7',\n",
              " 'silabs-thunderboard2',\n",
              " 'silabs-xg24',\n",
              " 'himax-ism',\n",
              " 'himax-we-i',\n",
              " 'himax-we-i-gnu',\n",
              " 'himax-wiseeye2',\n",
              " 'infineon-cy8ckit-062s2',\n",
              " 'infineon-cy8ckit-062-ble',\n",
              " 'runner-linux-armv7-microchip-sama7',\n",
              " 'nordic-nrf52840-dk',\n",
              " 'nordic-nrf5340-dk',\n",
              " 'nordic-nrf9160-dk',\n",
              " 'nordic-thingy53',\n",
              " 'nordic-thingy53-nrf7002eb',\n",
              " 'nordic-thingy91',\n",
              " 'nordic-nrf7002-dk',\n",
              " 'nordic-nrf9161-dk',\n",
              " 'nordic-nrf9151-dk',\n",
              " 'nordic-axons-cli',\n",
              " 'nordic-nrf54lm20-pdk',\n",
              " 'nordic-nrf54l15-dk',\n",
              " 'openmv',\n",
              " 'openmv-fw',\n",
              " 'sony-spresense',\n",
              " 'sony-spresense-commonsense',\n",
              " 'ti-launchxl',\n",
              " 'synaptics-ka10000',\n",
              " 'renesas-ck-ra6m5',\n",
              " 'brickml',\n",
              " 'brickml-module',\n",
              " 'renesas-ek-ra8d1',\n",
              " 'renesas-ek-ra8d1-sdram',\n",
              " 'alif-ensemble-e1c',\n",
              " 'alif-ensemble-e7',\n",
              " 'alif-ensemble-e7-he',\n",
              " 'alif-ensemble-e7-hp-sram',\n",
              " 'alif-ensemble-e7-devkit',\n",
              " 'alif-ensemble-e7-he-devkit',\n",
              " 'alif-ensemble-e7-hp-sram-devkit',\n",
              " 'seeed-grove-vision-ai',\n",
              " 'seeed-sensecap',\n",
              " 'runner-linux-aarch64',\n",
              " 'runner-linux-armv7',\n",
              " 'runner-linux-x86_64',\n",
              " 'runner-linux-aarch64-akd1000',\n",
              " 'runner-linux-x86_64-akd1000',\n",
              " 'runner-linux-x86_64-memryx-mx3',\n",
              " 'runner-linux-aarch64-nxp-imx93',\n",
              " 'runner-linux-aarch64-memryx-mx3',\n",
              " 'runner-linux-aarch64-qnn',\n",
              " 'runner-linux-aarch64-gpu',\n",
              " 'qualcomm-gstreamer-ml-pipeline-eim',\n",
              " 'runner-mac-x86_64',\n",
              " 'runner-mac-arm64',\n",
              " 'runner-linux-aarch64-rzv2l',\n",
              " 'runner-linux-aarch64-rzv2l-tvm',\n",
              " 'runner-linux-aarch64-rzv2h-tvm',\n",
              " 'runner-linux-aarch64-tda4vm',\n",
              " 'runner-linux-aarch64-am62a',\n",
              " 'particle',\n",
              " 'iar',\n",
              " 'runner-linux-aarch64-am68a',\n",
              " 'particle-p2',\n",
              " 'cmsis-package',\n",
              " 'runner-linux-aarch64-jetson-nano',\n",
              " 'runner-linux-aarch64-rzg2l',\n",
              " 'runner-linux-aarch64-jetson-orin',\n",
              " 'runner-linux-aarch64-jetson-orin-6-0',\n",
              " 'ceva-npn-lib',\n",
              " 'ceva-npn32',\n",
              " 'ceva-npn64',\n",
              " 'st-aton-lib',\n",
              " 'st-aton-lib-pack',\n",
              " 'st-stm32n6',\n",
              " 'st-stm32n6-cpu',\n",
              " 'runner-linux-aarch64-imdt-v2h']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# List the available profile target devices\n",
        "ei.model.list_deployment_targets()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "418ee00a-5714-4cd9-a880-2bdf567d72e5",
      "metadata": {
        "id": "418ee00a-5714-4cd9-a880-2bdf567d72e5"
      },
      "source": [
        "You should see a list printed such as:\n",
        "\n",
        "```\n",
        "['zip',\n",
        " 'arduino',\n",
        " 'tinkergen',\n",
        " 'cubemx',\n",
        " 'wasm',\n",
        " ...\n",
        " 'runner-linux-aarch64-tda4vm']\n",
        "```\n",
        "\n",
        "The most generic target is to download a .zip file that holds a C++ library containing the inference runtime and your trained model, so we choose `'zip'` from the above list. To do that, we first need to create a Classification object which contains our label strings (and other optional information about the model). These strings will be added to the C++ library metadata so you can access them in your edge application.\n",
        "\n",
        "Note that instead of writing the raw bytes to a file, you can also specify an `output_directory` argument in the `.deploy()` function. Your deployment file(s) will be downloaded to that directory.\n",
        "\n",
        "**Important!** The deployment targets list will change depending on the values provided for `model`, `model_output_type`, and `model_input_type` in the next part. For example, you will not see `openmv` listed once you upload a model (e.g. using `.profile()` or `.deploy()`) if `model_input_type` is not set to `ei.model.input_type.ImageInput()`. If you attempt to deploy to an unavailable target, you will receive the error `Could not deploy: deploy_target: ...`. If `model_input_type` is not provided, it will default to [OtherInput](https://docs.edgeimpulse.com/reference/python-sdk/edgeimpulse/model/input_type#otherinput). See [this page](https://docs.edgeimpulse.com/reference/python-sdk/edgeimpulse/model/input_type) for more information about input types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f45a3c73-fbc2-477a-9f8d-04c3e10b1863",
      "metadata": {
        "tags": [],
        "id": "f45a3c73-fbc2-477a-9f8d-04c3e10b1863",
        "outputId": "2e07b5c8-a37d-415a-bbbe-118892431353",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpxyltam7y/saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135769424670992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135769424673488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135769424673680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135769424674448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ],
      "source": [
        "# Set model information, such as your list of labels\n",
        "model_output_type = ei.model.output_type.Classification(labels=labels)\n",
        "\n",
        "# Set model input type\n",
        "model_input_type = ei.model.input_type.OtherInput()\n",
        "\n",
        "# Create C++ library with trained model\n",
        "deploy_bytes = None\n",
        "try:\n",
        "\n",
        "    deploy_bytes = ei.model.deploy(model=model,\n",
        "                                   model_output_type=model_output_type,\n",
        "                                   model_input_type=model_input_type,\n",
        "                                   deploy_target='zip')\n",
        "except Exception as e:\n",
        "    print(f\"Could not deploy: {e}\")\n",
        "\n",
        "# Write the downloaded raw bytes to a file\n",
        "if deploy_bytes:\n",
        "    with open(deploy_filename, 'wb') as f:\n",
        "        f.write(deploy_bytes.getvalue())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cRa5_UZ7I0Kw"
      },
      "id": "cRa5_UZ7I0Kw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "eddfdb39-215c-4f09-88d6-3e9c75ef3603",
      "metadata": {
        "tags": [],
        "id": "eddfdb39-215c-4f09-88d6-3e9c75ef3603"
      },
      "source": [
        "Your model C++ library should be downloaded as the file *my_model_cpp.zip* in the same directory as this notebook. You are now ready to use your C++ model in your embedded and edge device application! To use the C++ model for local inference, see our documentation [here](https://docs.edgeimpulse.com/docs/deployment/running-your-impulse-locally)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}